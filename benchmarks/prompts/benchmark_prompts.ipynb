{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b33f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7244dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "\n",
    "n_prompts = 100\n",
    "\n",
    "def save_jsonl(filename, items):\n",
    "  with open(filename, \"w\") as f:\n",
    "    for item in items:\n",
    "      f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439fa129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat prompts\n",
    "# https://huggingface.co/datasets/OpenAssistant/oasst1\n",
    "# https://github.com/LAION-AI/Open-Assistant/tree/main/oasst-data\n",
    "\n",
    "oasst = load_dataset(\"OpenAssistant/oasst1\", split=\"validation\")\n",
    "\n",
    "def extract_conversations(messages, num_conv=100):\n",
    "  conversations = []\n",
    "\n",
    "  for i, root in enumerate(msg for msg in messages if msg[\"parent_id\"] is None and msg[\"lang\"] == \"en\"):\n",
    "    current = root\n",
    "\n",
    "    conversation = []\n",
    "\n",
    "    while True:\n",
    "      conversation.append({\n",
    "          \"role\": \"user\" if current[\"role\"] == \"prompter\" else \"assistant\",\n",
    "          \"content\": current[\"text\"]})\n",
    "\n",
    "      try:\n",
    "        current = next(msg for msg in messages if msg[\"parent_id\"] == current[\"message_id\"])\n",
    "      except StopIteration:\n",
    "        break\n",
    "\n",
    "    conversations.append(conversation[:-1])\n",
    "\n",
    "    if i == num_conv - 1:\n",
    "      break\n",
    "\n",
    "  return conversations\n",
    "\n",
    "conversations = extract_conversations(oasst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83a554b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_payloads = []\n",
    "completion_payloads = []\n",
    "\n",
    "for conversation in conversations:\n",
    "  while len(conversations) > 0 and conversation[-1][\"role\"] == \"assistant\":\n",
    "    conversation.pop()\n",
    "\n",
    "  chat_payloads.append({\n",
    "    \"messages\": conversation\n",
    "  })\n",
    "\n",
    "  prompt = \"\\n\".join([\n",
    "    f\"User: {msg['content']}\" if msg[\"role\"] == \"user\" else\n",
    "    f\"Assistant: {msg['content']}\"\n",
    "    for msg in conversation])\n",
    "\n",
    "  completion_payloads.append({\n",
    "    \"prompt\": prompt + \"\\nAssistant:\"\n",
    "  })\n",
    "\n",
    "save_jsonl(\"chat_oasst1_chat.jsonl\", chat_payloads)\n",
    "save_jsonl(\"chat_oasst1_completion.jsonl\", completion_payloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarization prompts\n",
    "# https://huggingface.co/datasets/abisee/cnn_dailymail\n",
    "\n",
    "cnn = load_dataset(\"cnn_dailymail\", \"3.0.0\", split=\"validation\")\n",
    "\n",
    "chat_payloads = []\n",
    "completion_payloads = []\n",
    "\n",
    "for item in cnn.select(range(n_prompts)):\n",
    "  article = item[\"article\"]\n",
    "\n",
    "  chat_payloads.append({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the following article:\\n\\n{article}\"}\n",
    "    ]\n",
    "  })\n",
    "\n",
    "  completion_payloads.append({\n",
    "    \"prompt\": f\"Summarize the following article:\\n\\n{article}\\n\\nSummary:\"\n",
    "  })\n",
    "\n",
    "save_jsonl(\"summarization_cnn_chat.jsonl\", chat_payloads)\n",
    "save_jsonl(\"summarization_cnn_completion.jsonl\", completion_payloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762aa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QA prompts\n",
    "# https://huggingface.co/datasets/mandarjoshi/trivia_qa\n",
    "\n",
    "trivia = load_dataset(\"trivia_qa\", \"unfiltered\", split=\"validation\")\n",
    "\n",
    "chat_payloads = []\n",
    "completion_payloads = []\n",
    "\n",
    "for item in trivia.select(range(n_prompts)):\n",
    "  question = item[\"question\"]\n",
    "\n",
    "  chat_payloads.append({\n",
    "    \"messages\": [\n",
    "      {\"role\": \"user\", \"content\": question}\n",
    "    ]\n",
    "  })\n",
    "\n",
    "  prompt = f\"Q: {question}\\nA:\"\n",
    "  completion_payloads.append({\n",
    "    \"prompt\": prompt\n",
    "  })\n",
    "\n",
    "save_jsonl(\"qa_triviaqa_chat.jsonl\", chat_payloads)\n",
    "save_jsonl(\"qa_triviaqa_completion.jsonl\", completion_payloads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91c28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code generation prompts\n",
    "# https://huggingface.co/datasets/openai/openai_humaneval\n",
    "\n",
    "humaneval = load_dataset(\"openai_humaneval\", split=\"test\")\n",
    "\n",
    "chat_payloads = []\n",
    "completion_payloads = []\n",
    "\n",
    "for item in humaneval.select(range(n_prompts)):\n",
    "  prompt_code = item[\"prompt\"]\n",
    "\n",
    "  chat_payloads.append({\n",
    "    \"messages\": [\n",
    "      {\"role\": \"user\", \"content\": f\"Write a Python function based on the following signature:\\n\\n{prompt_code}\"}\n",
    "    ]\n",
    "  })\n",
    "\n",
    "  completion_payloads.append({\n",
    "    \"prompt\": f\"Write a Python function based on the following signature:\\n\\n{prompt_code}\\n\"\n",
    "  })\n",
    "\n",
    "save_jsonl(\"code_humaneval_chat.jsonl\", chat_payloads)\n",
    "save_jsonl(\"code_humaneval_completion.jsonl\", completion_payloads)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
